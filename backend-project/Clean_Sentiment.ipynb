{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87761c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c4ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cassi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527ccfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unify date formats and sort comments according to post date\n",
    "def unify_and_sort(comments):\n",
    "    for comment in comments:\n",
    "        if comment['date'][-1] == ':':\n",
    "            comment['date'] = comment['date'][:-1]\n",
    "        elif '-' in comment['date']:\n",
    "            comment['date'] = datetime.strptime(comment['date'], '%Y-%m-%d').strftime('%b %d %Y')\n",
    "          \n",
    "    comments.sort(key=lambda c: datetime.strptime(c['date'], \"%b %d %Y\"))\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d7c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of negative/neutral/positive comments of each talk\n",
    "def count_sentiment(scores):\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    for score in scores:\n",
    "        if score['compound'] > 0.4:\n",
    "            pos += 1\n",
    "        elif score['compound'] < -0.4:\n",
    "            neg += 1\n",
    "        else:\n",
    "            neu += 1\n",
    "            \n",
    "    return {'neg': neg, 'neu': neu, 'pos': pos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda368c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the original datasets\n",
    "talks1 = pd.read_json(\"ted_talks-10-Sep-2012.json\")\n",
    "talks2 = pd.read_json(\"ted_talks-25-Apr-2012.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(g for _, g in talks1.groupby('title') if len(g) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c398a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the first dataset\n",
    "talks1['views'] = talks1['views'].apply(lambda x: int(x[0].replace(',','')))\n",
    "talks1['title'] = talks1['title'].apply(lambda x: x[0])\n",
    "talks1['description'] = talks1['description'].apply(lambda x: ''.join(x).replace('\\t', '').replace('\\n', ' ').rstrip())\n",
    "talks1['collect_date'] = 'Sep 2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69211181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis of the comments in the first dataset\n",
    "talks1['filtered_comments'] = talks1['comments'].apply(lambda x: [{'text': d['text'], 'date': d['date']} for d in x])\n",
    "talks1['filtered_comments'] = talks1['filtered_comments'].apply(lambda x: unify_and_sort(x))\n",
    "talks1['scores'] = talks1['filtered_comments'].apply(lambda x: [sid.polarity_scores(c['text']) for c in x])\n",
    "talks1['sentiment_count'] = talks1['scores'].apply(lambda x: count_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(g for _, g in talks2.groupby('title') if len(g) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e419266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the second dataset\n",
    "talks2.drop([114, 1146, 690, 1145], inplace=True)\n",
    "talks2['description'] = talks2['description'].apply(lambda x: x.rstrip())\n",
    "talks2.reset_index(drop=True, inplace=True)\n",
    "talks2['collect_date'] = 'Apr 2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8bcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis of the comments in the second dataset\n",
    "talks2['filtered_comments'] = talks2['comments'].apply(lambda x: [{'text': d['text'], 'date': d['date']} for d in x])\n",
    "talks2['filtered_comments'] = talks2['filtered_comments'].apply(lambda x: unify_and_sort(x))\n",
    "talks2['scores'] = talks2['filtered_comments'].apply(lambda x: [sid.polarity_scores(c['text']) for c in x])\n",
    "talks2['sentiment_count'] = talks2['scores'].apply(lambda x: count_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "836350ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "talk_columns=['id','film_date','publish_date','title','speaker','ted_event','description','related_tags','related_themes','related_videos','views','comments','transcript','url', 'filtered_comments', 'scores', 'sentiment_count', 'collect_date']\n",
    "talks1 = talks1[talk_columns]\n",
    "talks2 = talks2[talk_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a3a7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "talks = talks2.append(talks1)\n",
    "talks.reset_index(drop=True, inplace=True)\n",
    "talks.drop(columns = ['id'], inplace=True)\n",
    "talks.to_csv('talks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0494bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_talks = pd.concat(g for _, g in talks.groupby('title') if len(g) > 1)\n",
    "repeated_talks.to_csv('repeated_talks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
